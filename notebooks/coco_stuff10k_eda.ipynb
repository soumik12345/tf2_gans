{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UOYnMrgmqNO"
   },
   "source": [
    "## Download Coco-Stuff initial version\n",
    "\n",
    "Homepage: https://github.com/nightrome/cocostuff10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lIYdn1woOS1n"
   },
   "outputs": [],
   "source": [
    "!wget -q http://calvin.inf.ed.ac.uk/wp-content/uploads/data/cocostuffdataset/cocostuff-10k-v1.1.zip\n",
    "!unzip -q cocostuff-10k-v1.1.zip -d dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmOZYSs9mzbm"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__r4JHdHQr-V"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNEb2oTpm0oP"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XupD4qe0S5MP"
   },
   "outputs": [],
   "source": [
    "PATH = \"dataset\"\n",
    "SPLIT = 0.1\n",
    "BATCH_SIZE = 16\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "NUM_CLASSES = 172  # https://github.com/nightrome/cocostuff10k#label-names--indices\n",
    "# Should this be 183?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUSJNlcXm1_w"
   },
   "source": [
    "## Load training and test filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "718d2ZNkUHRg"
   },
   "outputs": [],
   "source": [
    "train_names = np.loadtxt(f\"{PATH}/imageLists/train.txt\", dtype=str)\n",
    "np.random.shuffle(train_names)\n",
    "\n",
    "test_names = np.loadtxt(f\"{PATH}/imageLists/test.txt\", dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B83eZpaEm4hT"
   },
   "source": [
    "## Utility for creating dataset paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RjLmQVf6VQ7p"
   },
   "outputs": [],
   "source": [
    "def get_dataset_paths(filenames):\n",
    "    image_filepaths = [f\"{PATH}/images/{filename}.jpg\" for filename in filenames]\n",
    "    annotation_filepaths = [\n",
    "        f\"{PATH}/annotations/{filename}.mat\" for filename in filenames\n",
    "    ]\n",
    "    return image_filepaths, annotation_filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFhkIwu0m8Sg"
   },
   "source": [
    "## Create train/val/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJDRQkvAVpC5",
    "outputId": "68f8b7ab-307e-41e5-ff5d-817e72c6aa71"
   },
   "outputs": [],
   "source": [
    "train_image_paths, train_anno_paths = get_dataset_paths(train_names)\n",
    "split_index = int(len(train_image_paths) * (1 - SPLIT))\n",
    "new_train_image_paths = train_image_paths[:split_index]\n",
    "new_train_anno_paths = train_anno_paths[:split_index]\n",
    "\n",
    "val_image_paths = train_image_paths[split_index:]\n",
    "val_anno_paths = train_anno_paths[split_index:]\n",
    "\n",
    "test_image_paths, test_anno_paths = get_dataset_paths(test_names)\n",
    "\n",
    "print(f\"Total training samples: {len(new_train_image_paths)}.\")\n",
    "print(f\"Total validation samples: {len(val_image_paths)}.\")\n",
    "print(f\"Total test samples: {len(test_image_paths)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bObT2wg2WnpS",
    "outputId": "adf010c0-57c8-4339-cb1e-a171968e236b"
   },
   "outputs": [],
   "source": [
    "loadmat(new_train_anno_paths[0]).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIriC5vin5bV"
   },
   "source": [
    "Details about these keys can be found [here](https://github.com/nightrome/cocostuff10k#mat-format)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c96xfHYCm_aL"
   },
   "source": [
    "## Data input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHvJJ4JBY4Bd"
   },
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 127.5 - 1\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_annotation(annotation_path):\n",
    "    segmentation_map = loadmat(annotation_path)[\"S\"]\n",
    "    segmentation_map = segmentation_map.astype(\"float32\") / 127.5 - 1\n",
    "    return segmentation_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKtanTg6nBrX"
   },
   "source": [
    "### Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K613f6wNZp-q"
   },
   "outputs": [],
   "source": [
    "image_ds = tf.data.Dataset.from_tensor_slices(new_train_image_paths).map(\n",
    "    load_image, num_parallel_calls=AUTO\n",
    ")\n",
    "annotation_ds = tf.data.Dataset.from_tensor_slices(new_train_anno_paths)\n",
    "annotation_ds = annotation_ds.map(\n",
    "    lambda x: tf.numpy_function(load_annotation, [x], tf.float32),\n",
    "    num_parallel_calls=AUTO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "_2IJncMWaYjR",
    "outputId": "8b0378a7-c027-4767-dd6d-9381963b31c8"
   },
   "outputs": [],
   "source": [
    "for image in image_ds.take(1):\n",
    "    plt.imshow((image + 1) / 2)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "8cAOez_jairB",
    "outputId": "cc2ed8fc-0dc5-48da-fa21-aa5ca7256497"
   },
   "outputs": [],
   "source": [
    "for segmentation in annotation_ds.take(1):\n",
    "    plt.imshow((segmentation + 1) / 2)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45sty8Z6nFbH"
   },
   "source": [
    "### Pipeline utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1oaP24pCbpMQ"
   },
   "outputs": [],
   "source": [
    "def random_crop(size=(256, 256)):\n",
    "    def __pp(segmentation_map, image):\n",
    "        crop_size = tf.convert_to_tensor(size)\n",
    "\n",
    "        image_shape = tf.shape(image)[:2]\n",
    "        margins = image_shape - crop_size\n",
    "\n",
    "        y1 = tf.random.uniform(shape=(), maxval=margins[0], dtype=tf.int32)\n",
    "        x1 = tf.random.uniform(shape=(), maxval=margins[1], dtype=tf.int32)\n",
    "        y2 = y1 + crop_size[0]\n",
    "        x2 = x1 + crop_size[1]\n",
    "\n",
    "        labels = tf.identity(segmentation_map)\n",
    "        labels = ((labels + 1) / 2) * 255.0\n",
    "        labels = tf.cast(labels, tf.uint8)\n",
    "\n",
    "        cropped_images = []\n",
    "        images = [segmentation_map, image, labels]\n",
    "        for img in images:\n",
    "            cropped_images.append(img[y1:y2, x1:x2])\n",
    "        return cropped_images\n",
    "\n",
    "    return __pp\n",
    "\n",
    "\n",
    "def standard_resize(image_size=(256, 256)):\n",
    "    def __pp(segmentation_map, image):\n",
    "        segmentation_map.set_shape([None, None])\n",
    "        image.set_shape([None, None, 3])\n",
    "\n",
    "        segmentation_map = tf.image.resize(segmentation_map[..., None], image_size)\n",
    "        image = tf.image.resize(image, image_size)\n",
    "\n",
    "        labels = tf.identity(segmentation_map)\n",
    "        labels = ((labels + 1) / 2) * 255.0\n",
    "        labels = tf.cast(labels, tf.uint8)\n",
    "\n",
    "        return tf.squeeze(segmentation_map), image, tf.squeeze(labels)\n",
    "\n",
    "    return __pp\n",
    "\n",
    "\n",
    "def one_hot_encoding(segmentation_map, image, labels):\n",
    "    segmentation_map_ohe = tf.one_hot(labels, NUM_CLASSES)\n",
    "    return segmentation_map, image, segmentation_map_ohe\n",
    "\n",
    "\n",
    "def prepare_dataset(image_paths, annotation_paths, train=True):\n",
    "    image_ds = tf.data.Dataset.from_tensor_slices(image_paths).map(\n",
    "        load_image, num_parallel_calls=AUTO\n",
    "    )\n",
    "    annotation_ds = tf.data.Dataset.from_tensor_slices(annotation_paths)\n",
    "    annotation_ds = annotation_ds.map(\n",
    "        lambda x: tf.numpy_function(load_annotation, [x], tf.float32),\n",
    "        num_parallel_calls=AUTO,\n",
    "    ).cache()\n",
    "\n",
    "    dataset = tf.data.Dataset.zip((annotation_ds, image_ds))\n",
    "    dataset = dataset.shuffle(BATCH_SIZE * 10) if train else dataset\n",
    "    map_fn = random_crop() if train else standard_resize()\n",
    "    dataset = dataset.map(map_fn, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.map(one_hot_encoding, num_parallel_calls=AUTO)\n",
    "\n",
    "    return dataset.batch(BATCH_SIZE, drop_remainder=True).prefetch(AUTO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2IE0Wn4nHqw"
   },
   "source": [
    "## Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8TXXWe9eeJL"
   },
   "outputs": [],
   "source": [
    "training_set = prepare_dataset(new_train_image_paths, new_train_anno_paths)\n",
    "validation_set = prepare_dataset(val_image_paths, val_anno_paths, train=False)\n",
    "test_set = prepare_dataset(test_image_paths, test_anno_paths, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "focXK87BnI8s"
   },
   "source": [
    "## Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "24mP-Kvie2IA",
    "outputId": "464b61af-4417-4407-d0a7-ae090e09bbea"
   },
   "outputs": [],
   "source": [
    "sample_train_batch = next(iter(training_set))\n",
    "print(f\"Segmentation map batch shape: {sample_train_batch[0].shape}.\")\n",
    "print(f\"Image batch shape: {sample_train_batch[1].shape}.\")\n",
    "print(f\"One-hot encoded label map shape: {sample_train_batch[2].shape}.\")\n",
    "\n",
    "# Plot a view samples from the training set.\n",
    "for segmentation_map, real_image in zip(sample_train_batch[0], sample_train_batch[1]):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    fig.add_subplot(1, 2, 1).set_title(\"Segmentation Map\")\n",
    "    plt.imshow((segmentation_map + 1) / 2)\n",
    "    fig.add_subplot(1, 2, 2).set_title(\"Real Image\")\n",
    "    plt.imshow((real_image + 1) / 2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFKmVqU-VWE5",
    "outputId": "2179ef46-77d4-4e6a-b41a-e0baad553c06"
   },
   "outputs": [],
   "source": [
    "sample_validation_batch = next(iter(validation_set))\n",
    "print(f\"Segmentation map batch shape: {sample_validation_batch[0].shape}.\")\n",
    "print(f\"Image batch shape: {sample_validation_batch[1].shape}.\")\n",
    "print(f\"One-hot encoded label map shape: {sample_validation_batch[2].shape}.\")\n",
    "\n",
    "sample_test_batch = next(iter(test_set))\n",
    "print(f\"Segmentation map batch shape: {sample_test_batch[0].shape}.\")\n",
    "print(f\"Image batch shape: {sample_test_batch[1].shape}.\")\n",
    "print(f\"One-hot encoded label map shape: {sample_test_batch[2].shape}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wC3IRRErqxw"
   },
   "source": [
    "<font color=red>Question</font>: Is the label one-hot encoding scheme right?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "COCO-Stuff",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
